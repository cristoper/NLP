{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input\n",
    "return \n",
    "- training data\n",
    "- intermediate data\n",
    "- test data\n",
    "- sentence to decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_table(\"/Users/amyburkhardt/Dropbox/NLP Readings/hw 1/POS-training.txt\",'\\t', \n",
    "                      header=None, \n",
    "                      skip_blank_lines=False, \n",
    "                      keep_default_na = False,\n",
    "                      names = ['word_Num', 'word', 'tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_table(\"/Users/amyburkhardt/Dropbox/NLP Readings/hw 1/POS-test.txt\",'\\t', \n",
    "                      header=None, \n",
    "                      skip_blank_lines=False, \n",
    "                      keep_default_na = False,\n",
    "                      names = ['word_Num', 'word','tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_sent = ['the', 'dog', 'ate', 'the', 'food']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', \"'d\", 'like', 'to', 'go', 'to', 'a', 'fancy', 'restaurant', '.']"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Fixed Vocabulary and Tag Lists\n",
    "return \n",
    "- tag list\n",
    "- vocabuarly list called vocabulary\n",
    "- events list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tags = ['CC', 'CD',\n",
    "        'DT',\n",
    "        'EX',\n",
    "        'FW',\n",
    "        'IN', \n",
    "        'JJ', 'JJR', 'JJS',\n",
    "        'LS', \n",
    "        'MD',\n",
    "        'NN', 'NNS', 'NNP', 'NNPS',\n",
    "        'PDT', 'POS', 'PRP', 'PRP$',\n",
    "        'RB', 'RBR', 'RBS', 'RP',\n",
    "        'SYM', \n",
    "        'TO', \n",
    "        'UH', \n",
    "        'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ',\n",
    "        'WDT', 'WP', 'WP$', 'WRB', \n",
    "        '$', '#', '\"', '(', ')', ',', '.', ':'\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ngram_dict(data, ngrams = \"tag_word\"):\n",
    "    \"\"\"\n",
    "    Creates dict of ngrams (key) and count (value). \n",
    "    \n",
    "    Arguments: \n",
    "        data: DataFrame with 'tag' and 'word' colum\n",
    "        negrams: denote type of ngram (unigram or bigram) and if want words or tags: word_word or tag_word\n",
    "    Returns:\n",
    "        A dict where key is either a unigram or a bigram tuple, and value is the count of the ngrams\n",
    "    \"\"\"\n",
    "    if ngrams == \"tag_tag\":     \n",
    "        col_1 = data['tag']\n",
    "        col_2 = col_1[1:col_1.shape[0]]\n",
    "        ngram_count = list(zip(col_1, col_2))\n",
    "        ngram_count = dict(Counter(ngram_count))\n",
    "        ngram_count[('', col_1[0])] += 1\n",
    "\n",
    "    \n",
    "    if ngrams == \"tag_word\": # not really bi-grams, just getting count of tag,word\n",
    "        col_1 = data['word']\n",
    "        col_2 = data['tag']\n",
    "        ngram_count = list(zip(col_1, col_2))\n",
    "        ngram_count = dict(Counter(ngram_count))\n",
    "            \n",
    "    if ngrams == 'tag': \n",
    "        ngram_count = dict(Counter(data.tag))      \n",
    "        \n",
    "    if ngrams == 'word': \n",
    "        ngram_count = dict(Counter(data.word))\n",
    "            \n",
    "    return ngram_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get fixed vocabulary; identify which words will be considered UNKs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get words that we will call unknowns, and replace these instances in the dataframe\n",
    "unigrams = ngram_dict(train, \"word\")\n",
    "unknowns = { key:value for key, value in unigrams.items() if value < 2 }\n",
    "unknowns = unknowns.fromkeys(unknowns, 'UNK')\n",
    "# replace words that appear less than three times with UNK in training data\n",
    "train['word'] = train['word'].replace(unknowns)\n",
    "#get list of vocabulary \n",
    "vocab = ngram_dict(train, \"word\")\n",
    "vocabulary = list(vocab.keys())\n",
    "vocabulary.remove('') # remove spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Return index of the words in the new sentece from the fixed vocabuarly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "dog\n",
      "ate\n",
      "the\n",
      "food\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[561, 675, 675, 561, 617]"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events = []\n",
    "for word in new_sent:\n",
    "    print(word)\n",
    "    try: \n",
    "        events.append(vocabulary.index(word))\n",
    "    except: events.append(vocabulary.index('UNK'))\n",
    "events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Transition and Observation Matrices\n",
    "return\n",
    "-tran matrix\n",
    "-observation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_transition_matrix (tags, bigram_counts, unigram_counts):\n",
    "    \"\"\"\n",
    "    Compute probabilities for the transition matrix (len(tags)+1 x len(tags))\n",
    "    \n",
    "    Arguments: \n",
    "        tags: POS tags (that may or may not appear in training data)\n",
    "        bigram_counts: count of bigrams of POS tags in training data (used for numerator)\n",
    "        unigram_counts: count of unigram POS tag in training data (used for denominator)\n",
    "        \n",
    "    Returns: 45 x 44 matrix of transition probabilities for all possible POS tags\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    transition = [] # list of transition probabilities \n",
    "    \n",
    "    # first compute the starting probabilities \n",
    "\n",
    "    for x in tags: \n",
    "            pair = ('',x) # here the period denotes the start of a sentence. Not very confident about this\n",
    "            denominator = unigram_counts[''] + len(tags)\n",
    "            try: \n",
    "                 numerator = bigram_counts[pair] + 1 \n",
    "            except:\n",
    "                 numerator = 1\n",
    "            transition.append(numerator / denominator)\n",
    "\n",
    "\n",
    "    # then compute everything else \n",
    "    \n",
    "    for x in tags:\n",
    "        for y in tags:\n",
    "            pair = (x,y)\n",
    "            try:\n",
    "                denominator = unigram_counts[x] + len(tags)\n",
    "            except: \n",
    "                denominator = len(tags)\n",
    "            try: \n",
    "                numerator = bigram_counts[pair] + 1 \n",
    "            except:\n",
    "                numerator = 1 \n",
    "            transition.append(numerator / denominator)\n",
    "   \n",
    "    \n",
    "    transition = np.array(transition)\n",
    "    tran_matrix = transition.reshape(len(tags)+1, len(tags))\n",
    "    \n",
    "    return tran_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.00006692,  1.        ,  1.        ,  0.99666954,  1.        ,\n",
       "        0.96741855,  1.        ,  0.99540975,  1.        ,  1.        ,\n",
       "        0.83018868,  1.        ,  0.98220943,  0.99804061,  0.97260274,\n",
       "        1.        ,  1.        ,  1.        ,  0.99967685,  1.        ,\n",
       "        0.99453552,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  0.99934645,  1.        ,  1.        ,\n",
       "        0.9908046 ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  0.00294413,  1.        ])"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_tag_counts = ngram_dict(train, \"tag_tag\")\n",
    "unigram_tag_counts = ngram_dict(train, \"tag\")\n",
    "transitions = compute_transition_matrix (tags, bigram_tag_counts, unigram_tag_counts)\n",
    "np.sum(transitions, axis = 1) # confirm that most rows sum closely to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_observation_matrix (tags, vocabulary, bigram_counts, unigram_counts):\n",
    "    \"\"\"\n",
    "    Compute probabilities for the observation matrix (tags, vocabulary)\n",
    "    \n",
    "    Arguments: \n",
    "        tags: POS tags (that may or may not appear in training data)\n",
    "        vocabulary: words that appear in the training set. Any words that appear less than 2 times = UNK\n",
    "        bigram_counts: count of bigrams of (tag, word) (used for numerator)\n",
    "        unigram_counts: count of unigram POS tag in training data (used for denominator)\n",
    "        \n",
    "    Returns: len(tags) x len(vocabulary) matrix of transition probabilities for all possible POS tags\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    observations = [] # list of observation likelihoods\n",
    "    for x in tags: \n",
    "        for y in vocabulary:\n",
    "            pair = (y, x)\n",
    "            try: \n",
    "                denominator = unigram_counts[x] + len(vocabulary)\n",
    "            except: \n",
    "                 denominator = len(vocabulary)\n",
    "            try: \n",
    "                 numerator = bigram_counts[pair] + 1\n",
    "            except: numerator = 1\n",
    "            observations.append(numerator / denominator)\n",
    "            \n",
    "    observations = np.array(observations)\n",
    "    obs_matrix = observations.reshape(len(tags),len(vocabulary))  \n",
    "    return obs_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bigram_counts = ngram_dict(train, \"tag_word\")\n",
    "unigram_counts = ngram_dict(train, \"tag\")\n",
    "observations = compute_observation_matrix(tags, vocabulary, bigram_counts, unigram_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(observations, axis = 1) # confirm that most rows sum closely to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viterbi Algorithm\n",
    "return\n",
    "-predicted POS tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def viterbi (transition, observations, events):\n",
    "    \"\"\" Computes sequnce of hidden states, given observed events.\n",
    "    Arguments: \n",
    "        transition: transition matrix with start probabilites as first row\n",
    "        observations: observation liklihood matrix, with states as rows, and vocabulary as columns\n",
    "        events: sequence of observed events\n",
    "        \n",
    "    Returns: \n",
    "        generator, which yields the states\n",
    "    \"\"\"\n",
    "    \n",
    "    n_states = transition.shape[1]\n",
    "    n_events = len(events)\n",
    "    v = np.zeros((n_states, n_events))\n",
    "    bp = v.copy()\n",
    "    \n",
    "    # initialization step\n",
    "    for s in range(n_states):\n",
    "        v[s,0] = tran[0,s] * observations[s, events[0]]\n",
    "\n",
    "    # induction step\n",
    "    for t in range (1, n_events):\n",
    "        for s in range(n_states):\n",
    "            tmp = []\n",
    "            for s_prime in range (n_states): \n",
    "                prev_t = v[s_prime, t-1]\n",
    "                tran_s_prime_to_s = tran[s_prime + 1, s]\n",
    "                obser_s_given_t = observations[s, events[t]]\n",
    "                tmp.append(prev_t * tran_s_prime_to_s *obser_s_given_t) # still need to changet thos to adding logs\n",
    "            # now that all interim probabilities have been computed for given state, get max\n",
    "            # and also store the index of the argmax\n",
    "            v[s,t] = max(tmp)\n",
    "            bp[s,t] = np.argmax(tmp)\n",
    "\n",
    "    # termination step\n",
    "    q = np.argmax(v[:, n_events-1]) # want to get the argmax of the final time -- it will return a state index\n",
    "\n",
    "    # back reference step \n",
    "    for i in reversed(range(n_events)):\n",
    "        yield q\n",
    "        q = int(bp[q,i])\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sequence(viterbi_gen, names_events):\n",
    "    \"\"\" translate viterbi generater into a sequence of state anme\n",
    "    \"\"\"\n",
    "    sequence = []\n",
    "    for state in viterbi_gen:\n",
    "        name = names_events[state]\n",
    "        sequence.insert(0, name)\n",
    "        \n",
    "    return(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagger = viterbi(transitions, observations, events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DT', 'NN', 'VBZ', 'DT', 'NN']"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sequence(tagger, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = train['word'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sent(seq, sep):\n",
    "    g = []\n",
    "    for el in seq:\n",
    "        if el == sep:\n",
    "            yield g\n",
    "            g = []\n",
    "        g.append(el)\n",
    "    yield g\n",
    "    \n",
    "\n",
    "result = list(sent(sentences, ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_events(new_sent):\n",
    "    events = []\n",
    "    for word in new_sent:\n",
    "        try: \n",
    "            events.append(vocabulary.index(word))\n",
    "        except: events.append(vocabulary.index('UNK'))\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_pos = []\n",
    "counter = 0\n",
    "for new_sent in result:\n",
    "    if counter > 0: \n",
    "        new_sent.pop(0)\n",
    "    tagger = viterbi(transitions, observations, get_events(new_sent))\n",
    "    sequence = get_sequence(tagger, tags)\n",
    "    sequence.insert(len(sequence), '') #add space at the end\n",
    "    all_pos.append(sequence)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list = [item for sublist in all_pos for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRP',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'RB',\n",
       " 'JJ',\n",
       " '.',\n",
       " '',\n",
       " 'RB',\n",
       " 'RB',\n",
       " 'RB',\n",
       " 'RB',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VB',\n",
       " '.',\n",
       " '',\n",
       " 'RB',\n",
       " 'RB',\n",
       " 'RB',\n",
       " 'RB',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VB',\n",
       " '.',\n",
       " '',\n",
       " 'RB',\n",
       " 'RB',\n",
       " 'RB',\n",
       " 'RB',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VB',\n",
       " '.',\n",
       " '',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'RB',\n",
       " 'RB',\n",
       " 'IN',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'IN',\n",
       " 'FW',\n",
       " 'FW',\n",
       " 'FW',\n",
       " '.',\n",
       " '',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'IN',\n",
       " 'FW',\n",
       " 'FW',\n",
       " 'FW',\n",
       " '.',\n",
       " '',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'IN',\n",
       " 'FW',\n",
       " 'FW',\n",
       " 'FW',\n",
       " '.',\n",
       " '',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'IN',\n",
       " 'FW',\n",
       " 'FW',\n",
       " 'FW',\n",
       " '.',\n",
       " '',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'IN',\n",
       " 'FW',\n",
       " 'FW',\n",
       " 'FW',\n",
       " '.',\n",
       " '',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNPS',\n",
       " 'NNPS',\n",
       " 'NNPS',\n",
       " 'NNP',\n",
       " '.',\n",
       " '',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNPS',\n",
       " 'NNPS',\n",
       " 'NNPS',\n",
       " 'NNP',\n",
       " '.',\n",
       " '',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNPS',\n",
       " 'NNPS',\n",
       " 'NNPS',\n",
       " 'NNP',\n",
       " '.',\n",
       " '',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNPS',\n",
       " 'NNPS',\n",
       " 'NNPS',\n",
       " 'NNP',\n",
       " '.',\n",
       " '',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'RB',\n",
       " '.',\n",
       " '',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'VB',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'RB',\n",
       " '.',\n",
       " '',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'VB',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'RB',\n",
       " '.',\n",
       " '',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'RB',\n",
       " 'JJ',\n",
       " 'IN',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'NN',\n",
       " 'RB',\n",
       " '.',\n",
       " '',\n",
       " 'VB',\n",
       " 'RP',\n",
       " '.',\n",
       " '',\n",
       " 'VB',\n",
       " 'RP',\n",
       " '.',\n",
       " '',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'RB',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'RB',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'RB',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'RB',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'WP',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'VBP',\n",
       " 'PRP',\n",
       " 'VB',\n",
       " 'RB',\n",
       " '.',\n",
       " '',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'RB',\n",
       " '.',\n",
       " '',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'RB',\n",
       " '.',\n",
       " '',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'RB',\n",
       " '.',\n",
       " '',\n",
       " 'IN',\n",
       " 'CD',\n",
       " 'NNS',\n",
       " '.',\n",
       " '',\n",
       " 'IN',\n",
       " 'CD',\n",
       " 'NNS',\n",
       " '.',\n",
       " '',\n",
       " 'CD',\n",
       " 'NNS',\n",
       " 'RB',\n",
       " '.',\n",
       " '',\n",
       " 'CD',\n",
       " 'NNS',\n",
       " 'RB',\n",
       " '.',\n",
       " '',\n",
       " 'PRP',\n",
       " 'VBD',\n",
       " 'CD',\n",
       " 'NNS',\n",
       " '.',\n",
       " '',\n",
       " 'PRP',\n",
       " 'VBD',\n",
       " 'CD',\n",
       " 'NNS',\n",
       " '.',\n",
       " '',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'IN',\n",
       " 'PDT',\n",
       " 'DT',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'TO',\n",
       " 'VB',\n",
       " '.',\n",
       " '',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'IN',\n",
       " 'PDT',\n",
       " 'DT',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'TO',\n",
       " 'VB',\n",
       " '.',\n",
       " '',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'IN',\n",
       " 'PDT',\n",
       " 'DT',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'TO',\n",
       " 'VB',\n",
       " '.',\n",
       " '',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'IN',\n",
       " 'PDT',\n",
       " 'DT',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'TO',\n",
       " 'VB',\n",
       " '.',\n",
       " '',\n",
       " 'VBZ',\n",
       " 'DT',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'TO',\n",
       " 'VB',\n",
       " '.',\n",
       " '',\n",
       " 'VBZ',\n",
       " 'DT',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'TO',\n",
       " 'VB',\n",
       " '.',\n",
       " '',\n",
       " 'VBZ',\n",
       " 'DT',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'TO',\n",
       " 'VB',\n",
       " '.',\n",
       " '',\n",
       " 'VBZ',\n",
       " 'DT',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'TO',\n",
       " 'VB',\n",
       " '.',\n",
       " '',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'UH',\n",
       " '.',\n",
       " '',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'UH',\n",
       " '.',\n",
       " '',\n",
       " 'UH',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'JJR',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'UH',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'JJR',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'UH',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'JJR',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'UH',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'JJR',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'VB',\n",
       " 'RP',\n",
       " '.',\n",
       " '',\n",
       " 'VB',\n",
       " 'RP',\n",
       " '.',\n",
       " '',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'DT',\n",
       " 'RB',\n",
       " 'JJ',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'RB',\n",
       " 'RB',\n",
       " '.',\n",
       " '',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'DT',\n",
       " 'RB',\n",
       " 'JJ',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'RB',\n",
       " 'RB',\n",
       " '.',\n",
       " '',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'DT',\n",
       " 'RB',\n",
       " 'JJ',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'RB',\n",
       " 'RB',\n",
       " '.',\n",
       " '',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'DT',\n",
       " 'RB',\n",
       " 'JJ',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'RB',\n",
       " 'RB',\n",
       " '.',\n",
       " '',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'PRP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'PRP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'IN',\n",
       " 'CD',\n",
       " 'NNS',\n",
       " 'POS',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'IN',\n",
       " 'CD',\n",
       " 'NNS',\n",
       " 'POS',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'IN',\n",
       " 'NNP',\n",
       " '.',\n",
       " '',\n",
       " 'NNP',\n",
       " '.',\n",
       " '',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'VB',\n",
       " 'RP',\n",
       " '.',\n",
       " '',\n",
       " 'VB',\n",
       " 'RP',\n",
       " '.',\n",
       " '',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'NN',\n",
       " 'UH',\n",
       " '.',\n",
       " '',\n",
       " 'NN',\n",
       " 'UH',\n",
       " '.',\n",
       " '',\n",
       " 'PRP',\n",
       " 'VBZ',\n",
       " 'RB',\n",
       " 'RB',\n",
       " 'VB',\n",
       " '.',\n",
       " '',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'PRP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'RB',\n",
       " 'RB',\n",
       " 'RB',\n",
       " '.',\n",
       " '',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'PRP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'RB',\n",
       " 'RB',\n",
       " 'RB',\n",
       " '.',\n",
       " '',\n",
       " 'PRP',\n",
       " 'VBD',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'PRP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'PRP',\n",
       " 'VBD',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'PRP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'PRP',\n",
       " 'VBD',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'PRP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'RB',\n",
       " 'RB',\n",
       " '.',\n",
       " '',\n",
       " 'RB',\n",
       " 'RB',\n",
       " '.',\n",
       " '',\n",
       " 'IN',\n",
       " 'CD',\n",
       " 'NNS',\n",
       " 'POS',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'IN',\n",
       " 'CD',\n",
       " 'NNS',\n",
       " 'POS',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'VB',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'RB',\n",
       " '.',\n",
       " '',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'VB',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'RB',\n",
       " '.',\n",
       " '',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'VB',\n",
       " 'RP',\n",
       " '.',\n",
       " '',\n",
       " 'VB',\n",
       " 'RP',\n",
       " '.',\n",
       " '',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'NN',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'NN',\n",
       " 'CC',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'RB',\n",
       " 'VB',\n",
       " 'WRB',\n",
       " 'JJ',\n",
       " 'PRP',\n",
       " 'VBZ',\n",
       " '.',\n",
       " '',\n",
       " 'NN',\n",
       " 'CC',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'RB',\n",
       " 'VB',\n",
       " 'WRB',\n",
       " 'JJ',\n",
       " 'PRP',\n",
       " 'VBZ',\n",
       " '.',\n",
       " '',\n",
       " 'NN',\n",
       " 'CC',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'RB',\n",
       " 'VB',\n",
       " 'WRB',\n",
       " 'JJ',\n",
       " 'PRP',\n",
       " 'VBZ',\n",
       " '.',\n",
       " '',\n",
       " 'NN',\n",
       " 'CC',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'RB',\n",
       " 'VB',\n",
       " 'WRB',\n",
       " 'JJ',\n",
       " 'PRP',\n",
       " 'VBZ',\n",
       " '.',\n",
       " '',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'CC',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'CC',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'CC',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'CC',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'RB',\n",
       " 'VB',\n",
       " 'WP',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'RB',\n",
       " 'VB',\n",
       " 'WP',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'PRP',\n",
       " 'VBZ',\n",
       " 'RB',\n",
       " 'VB',\n",
       " '.',\n",
       " '',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'RB',\n",
       " 'VB',\n",
       " '.',\n",
       " '',\n",
       " 'VBZ',\n",
       " 'RB',\n",
       " 'VB',\n",
       " '.',\n",
       " '',\n",
       " 'WRB',\n",
       " 'IN',\n",
       " 'NN',\n",
       " '.',\n",
       " '',\n",
       " 'VB',\n",
       " 'RP',\n",
       " '.',\n",
       " '',\n",
       " 'VB',\n",
       " 'RP',\n",
       " '.',\n",
       " '',\n",
       " 'UH',\n",
       " 'PRP$',\n",
       " 'NNS',\n",
       " 'VBP',\n",
       " 'VBG',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'CC',\n",
       " ...]"
      ]
     },
     "execution_count": 676,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'col':flat_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'col':flat_list})\n",
    "train['tag'] = df\n",
    "\n",
    "train.to_csv(\"/Users/amyburkhardt/Dropbox/NLP Readings/hw 1/out_train.txt\", sep='\\t', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to do list\n",
    "1. make sure I am adding the log of the probabilities, instead of multiplying probabilties in viterbi (and that it still works)\n",
    "2. TONIGHT: write function to print tags from get_sequence into .txt file in a format that can then read in and evaluated by eval.py\n",
    "3. place code in final .py file (make it pretty if have time)\n",
    "4. upon working code, evaluate both training and intermediate test data files\n",
    "5. recompute transition and observation tables with entire training set\n",
    "6. MONDAY NIGHT: wait for final test set to run through system\n",
    "7. MONDAY NIGHT: write up report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
