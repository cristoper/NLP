{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-of-Speech Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from numpy import genfromtxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create transition properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dropbox = os.path.expanduser('~/Dropbox/')\n",
    "tran = genfromtxt(dropbox + 'NLP Readings/hw 1/test_POS_book_example/test_transitions.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.76700000e-01,   6.00000000e-04,   3.10000000e-03,\n",
       "          4.53000000e-02,   4.49000000e-02,   5.10000000e-02,\n",
       "          2.02600000e-01],\n",
       "       [  3.77700000e-01,   1.10000000e-02,   9.00000000e-04,\n",
       "          8.40000000e-03,   5.84000000e-02,   9.00000000e-03,\n",
       "          2.50000000e-03],\n",
       "       [  8.00000000e-04,   2.00000000e-04,   7.96800000e-01,\n",
       "          5.00000000e-04,   8.00000000e-04,   1.69800000e-01,\n",
       "          4.10000000e-03],\n",
       "       [  3.22000000e-02,   5.00000000e-04,   5.00000000e-03,\n",
       "          8.37000000e-02,   6.15000000e-02,   5.14000000e-02,\n",
       "          2.23100000e-01],\n",
       "       [  3.66000000e-02,   4.00000000e-04,   1.00000000e-04,\n",
       "          7.33000000e-02,   4.50900000e-01,   3.60000000e-03,\n",
       "          3.60000000e-03],\n",
       "       [  9.60000000e-03,   1.76000000e-02,   1.40000000e-03,\n",
       "          8.60000000e-03,   1.21600000e-01,   1.77000000e-02,\n",
       "          6.80000000e-03],\n",
       "       [  6.80000000e-03,   1.02000000e-02,   1.01100000e-01,\n",
       "          1.01200000e-01,   1.20000000e-02,   7.28000000e-02,\n",
       "          4.79000000e-02],\n",
       "       [  1.14700000e-01,   2.10000000e-03,   2.00000000e-04,\n",
       "          2.15700000e-01,   4.74400000e-01,   1.02000000e-02,\n",
       "          1.70000000e-03]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tran"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create observations likelihood. Include all, and then index what you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "observations = genfromtxt(dropbox + 'NLP Readings/hw 1/test_POS_book_example/test_observations.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.20000000e-05,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   3.08431000e-01,   2.80000000e-05,\n",
       "          0.00000000e+00,   2.00000000e-04,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   6.72000000e-04,\n",
       "          3.40000000e-04,   2.23000000e-04,   1.04460000e-02,\n",
       "          0.00000000e+00],\n",
       "       [  4.80000000e-05,   0.00000000e+00,   0.00000000e+00,\n",
       "          9.70000000e-05,   6.00000000e-06,   0.00000000e+00,\n",
       "          5.06099000e-01],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   2.80000000e-05,\n",
       "          0.00000000e+00,   2.33700000e-03,   0.00000000e+00,\n",
       "          0.00000000e+00]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations  = observations.transpose()\n",
    "observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create empty dataframe that is two rows, and three columns (one column per observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = np.zeros((observations.transpose().shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 7)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 7)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NNP', 'MD', 'VB', 'JJ', 'NN', 'RB', 'DT']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unobserved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unobserved = ['NNP', 'MD','VB','JJ','NN','RB','DT']\n",
    "events = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path of most likely states:\n",
      "NNP -> MD -> VB -> DT -> NN\n",
      "\n",
      "Not that this is NOT (necessarily) the same as taking the max of each individual state column:\n",
      "NNP -> MD -> RB -> DT -> NN\n"
     ]
    }
   ],
   "source": [
    "probs = []\n",
    "\n",
    "# best_ind should be the same size as df\n",
    "# Each column stores the most likely states for time t\n",
    "# Each row corresponds to a state (HOT, COLD) and stores the most likely previous state (HOT=0, COLD=1)\n",
    "best_ind = np.zeros((observations.transpose().shape))\n",
    "\n",
    "# begin in the first column by setting the Viterbi value in each\n",
    "# cell to the product of the transition probability and\n",
    "# the observation probability\n",
    "for i in range(0,len(unobserved)):\n",
    "    df [i,0] = tran[0,i] * observations[events[0]-1,i]\n",
    "    index = np.argmax(df [i,0])\n",
    "    best_ind[i][0] = index\n",
    "\n",
    "\n",
    "# move on column by column (vocabulary by vocabulary)\n",
    "for t in range(1\n",
    "               ,len(events)):    \n",
    "    for j in range(0,len(unobserved)):\n",
    "        for k in range (0,len(unobserved)):\n",
    "            # compute the probability of moving into each state\n",
    "            # previous Viterbi path probability from previous step (df [j,t-1])\n",
    "            prev = df[k, t-1]\n",
    "                \n",
    "            # the state observation likelihood (observations [k,t])\n",
    "            event = events[t]-1 # minus 1 because the index into observations should start at 0\n",
    "            obs_prob = observations[event, j]\n",
    "            \n",
    "            # the transition probability\n",
    "            tran_prob = tran[k+1, j] # k+1 because the first row of tran is the start probabilities\n",
    "            \n",
    "            prob = obs_prob * prev * tran_prob\n",
    "            probs.append(prob)\n",
    "            \n",
    "        # select the largest probability for moving into each state to be stored\n",
    "        # in table -- max sure to turn zeros into nan\n",
    "        \n",
    "        df[j,t] = max(probs)\n",
    "\n",
    "        # get the index of which state had the larger probabilty: zero probabily\n",
    "        index = np.argmax(probs)\n",
    "        best_ind[j][t] = index\n",
    "        probs = []\n",
    "\n",
    "# termination step:\n",
    "T = len(events) - 1\n",
    "final_prob = max(df[:, T]) # we never use this\n",
    "back = np.argmax(df[:,T]) # The most likely state for our final observation\n",
    "\n",
    "# backtrack:\n",
    "state_path = []\n",
    "for i in reversed(range(len(best_ind[1]))):\n",
    "    # Add the state corresponding to back to the beginning of state_path list:\n",
    "    state_path.insert(0, unobserved[back])\n",
    "    \n",
    "    # backtrack: get the most likely state for the previous\n",
    "    # step based on this one:\n",
    "    back = int(best_ind[back, i])\n",
    "\n",
    "print(\"Path of most likely states:\")\n",
    "print(\" -> \".join(state_path))\n",
    "print()\n",
    "print(\"Not that this is NOT (necessarily) the same as taking the max of each individual state column:\")\n",
    "test = df.transpose()\n",
    "best_unobserved = []\n",
    "for i in range(1,6):\n",
    "    maximum = np.argmax(test[i-1:i])\n",
    "    best_unobserved.append(unobserved[maximum])\n",
    "print(\" -> \".join(best_unobserved))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
