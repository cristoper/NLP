{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-of-Speech Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import genfromtxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create transition properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran = genfromtxt('~/Dropbox/NLP Readings/hw 1/test_POS_book_example/test_transitions.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.76700000e-01,   6.00000000e-04,   3.10000000e-03,\n",
       "          4.53000000e-02,   4.49000000e-02,   5.10000000e-02,\n",
       "          2.02600000e-01],\n",
       "       [  3.77700000e-01,   1.10000000e-02,   9.00000000e-04,\n",
       "          8.40000000e-03,   5.84000000e-02,   9.00000000e-03,\n",
       "          2.50000000e-03],\n",
       "       [  8.00000000e-04,   2.00000000e-04,   7.96800000e-01,\n",
       "          5.00000000e-04,   8.00000000e-04,   1.69800000e-01,\n",
       "          4.10000000e-03],\n",
       "       [  3.22000000e-02,   5.00000000e-04,   5.00000000e-03,\n",
       "          8.37000000e-02,   6.15000000e-02,   5.14000000e-02,\n",
       "          2.23100000e-01],\n",
       "       [  3.66000000e-02,   4.00000000e-04,   1.00000000e-04,\n",
       "          7.33000000e-02,   4.50900000e-01,   3.60000000e-03,\n",
       "          3.60000000e-03],\n",
       "       [  9.60000000e-03,   1.76000000e-02,   1.40000000e-03,\n",
       "          8.60000000e-03,   1.21600000e-01,   1.77000000e-02,\n",
       "          6.80000000e-03],\n",
       "       [  6.80000000e-03,   1.02000000e-02,   1.01100000e-01,\n",
       "          1.01200000e-01,   1.20000000e-02,   7.28000000e-02,\n",
       "          4.79000000e-02],\n",
       "       [  1.14700000e-01,   2.10000000e-03,   2.00000000e-04,\n",
       "          2.15700000e-01,   4.74400000e-01,   1.02000000e-02,\n",
       "          1.70000000e-03]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tran"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create observations likelihood. Include all, and then index what you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "observations = genfromtxt('~/Dropbox/NLP Readings/hw 1/test_POS_book_example/test_observations.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations  = observations.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create empty dataframe that is two rows, and three columns (one column per observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = np.zeros((observations.transpose().shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 7)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 7)"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unobserved = ['NNP', 'MD','VB','JJ','NN','RB','DT']\n",
    "events = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT\n",
      "VB\n",
      "MD\n",
      "NNP\n",
      "NNP\n",
      "[[  8.85440000e-06   0.00000000e+00   0.00000000e+00   2.48613983e-17\n",
      "    0.00000000e+00]\n",
      " [  0.00000000e+00   3.00406859e-08   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00]\n",
      " [  0.00000000e+00   2.23130880e-13   1.60852733e-11   0.00000000e+00\n",
      "    1.01707158e-20]\n",
      " [  0.00000000e+00   0.00000000e+00   5.10691660e-15   5.23057940e-16\n",
      "    0.00000000e+00]\n",
      " [  0.00000000e+00   1.03419392e-10   5.35925837e-15   5.93546583e-18\n",
      "    2.01357071e-15]\n",
      " [  0.00000000e+00   0.00000000e+00   5.32840899e-11   0.00000000e+00\n",
      "    0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   1.81619925e-12\n",
      "    0.00000000e+00]]\n",
      "[[ 0.  0.  0.  2.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  6.]\n",
      " [ 0.  0.  1.  5.  0.]\n",
      " [ 0.  0.  1.  2.  6.]\n",
      " [ 0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  2.  0.]]\n"
     ]
    }
   ],
   "source": [
    "probs = []\n",
    "\n",
    "# best_ind should be the same size as df\n",
    "# Each column stores the most likely states for time t\n",
    "# Each row corresponds to a state (HOT, COLD) and stores the most likely previous state (HOT=0, COLD=1)\n",
    "best_ind = np.zeros((observations.transpose().shape))\n",
    "\n",
    "# begin in the first column by setting the Viterbi value in each\n",
    "# cell to the product of the transition probability and\n",
    "# the observation probability\n",
    "for i in range(0,len(unobserved)):\n",
    "    df [i,0] = tran[0,i] * observations[events[0]-1,i]\n",
    "    index = np.argmax(df [i,0])\n",
    "    best_ind[i][0] = index\n",
    "\n",
    "\n",
    "# move on column by column (vocabulary by vocabulary)\n",
    "for t in range(1,len(events)):    \n",
    "    for j in range(0,len(unobserved)):\n",
    "        for k in range (0,len(unobserved)):\n",
    "            # compute the probability of moving into each state\n",
    "            # previous Viterbi path probability from previous step (df [j,t-1])\n",
    "            prev = df[k, t-1]\n",
    "                \n",
    "            # the state observation likelihood (observations [k,t])\n",
    "            event = events[t]-1 # minus 1 because the index into observations should start at 0\n",
    "            obs_prob = observations[event, j]\n",
    "            \n",
    "            # the transition probability\n",
    "            tran_prob = tran[k+1, j] # k+1 because the first row of tran is the start probabilities\n",
    "            \n",
    "            prob = obs_prob * prev * tran_prob\n",
    "            probs.append(prob)\n",
    "            \n",
    "        # select the largest probability for moving into each state to be stored\n",
    "        # in table -- max sure to turn zeros into nan\n",
    "\n",
    "        \n",
    "        df[j,t] = max(probs)\n",
    "        df[j,t]\n",
    "\n",
    "        # get the index of which state had the larger probabilty: zero probabily\n",
    "        index = np.argmax(probs)\n",
    "        best_ind[j][t] = index\n",
    "        probs = []\n",
    "\n",
    "# termination step:\n",
    "T = len(events) - 1\n",
    "final_prob = []\n",
    "for k in range(0,len(unobserved)):\n",
    "    final_prob.append(df[k, T] * tran[k+1, T])\n",
    "\n",
    "# backtrack:\n",
    "back = np.argmax(final_prob)\n",
    "for i in reversed(range(len(best_ind[1]))):\n",
    "    back = int(best_ind[back, i])\n",
    "    print(unobserved[back])\n",
    "\n",
    "print(df)\n",
    "print(best_ind)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
